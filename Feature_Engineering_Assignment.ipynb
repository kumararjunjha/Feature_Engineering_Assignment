{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a2dc84-a27e-4d73-b3da-b8d9ad643a80",
   "metadata": {},
   "source": [
    "                                                #Feature Engineering\n",
    "\n",
    "1. What is a parameter?\n",
    "    A parameter is a value that defines a model's behavior in Machine Learning (ML) or statistics. \n",
    "    It is learned from the training data during model training.\n",
    "\n",
    "\n",
    "2. What is correlation?\n",
    "    Correlation measures the relationship between two variables, indicating how one variable changes \n",
    "    with respect to another.\n",
    "\n",
    "Types of Correlation:\n",
    "Positive Correlation: When one variable increases, the other also increases (e.g., height vs. weight).\n",
    "Negative Correlation: When one variable increases, the other decreases (e.g., speed vs. travel time).\n",
    "No Correlation: When no relationship exists between the variables.\n",
    "Mathematical Measure:\n",
    "Correlation Coefficient (r) ranges from -1 to +1:\n",
    "r = +1 → Perfect positive correlation\n",
    "r = -1 → Perfect negative correlation\n",
    "r = 0 → No correlation\n",
    "\n",
    "3. What does negative correlation mean?\n",
    "    A negative correlation means that as one variable increases, the other decreases.\n",
    "\n",
    "4. Define Machine Learning. What are the main components in Machine Learning?\n",
    "    Machine Learning (ML) is a branch of artificial intelligence (AI) that enables systems to learn \n",
    "    patterns from data and make decisions without explicit programming.\n",
    "\n",
    "5. How does loss value help in determining whether the model is good or not?\n",
    "    The loss value represents the difference between the actual and predicted output.\n",
    "\n",
    "6. What are continuous and categorical variables?\n",
    "Continuous Variables:\n",
    "Numerical values that can take infinite possibilities (e.g., height, temperature, price).\n",
    "Example:\n",
    "temperature = [23.5, 27.8, 30.1, 35.0]\n",
    "Categorical Variables:\n",
    "Discrete groups or categories (e.g., colors, cities, gender).\n",
    "Example:\n",
    "color = ['Red', 'Blue', 'Green']\n",
    "\n",
    "7. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
    "    Since ML models work with numbers, categorical variables must be encoded.\n",
    "\n",
    "    Common Encoding Techniques:\n",
    "    Label Encoding\n",
    "\n",
    "    Assigns numerical labels to categories.\n",
    "Example: {'Male': 0, 'Female': 1}\n",
    "Good for: Ordinal Data (ordered categories).\n",
    "One-Hot Encoding (OHE)\n",
    "\n",
    "→ One-Hot Encoding:\n",
    "Red:   [1, 0, 0]\n",
    "Blue:  [0, 1, 0]\n",
    "Green: [0, 0, 1]\n",
    "Good for: Nominal Data (unordered categories).\n",
    "Target Encoding\n",
    "\n",
    "Replaces categories with the mean of the target variable.\n",
    "Example:\n",
    "City: [NY, LA, SF]\n",
    "Purchase Rate: [NY = 0.6, LA = 0.7, SF = 0.4]\n",
    "Frequency Encoding\n",
    "\n",
    "8. What do you mean by training and testing a dataset?\n",
    "    When building an ML model, we split the dataset into training and testing sets:\n",
    "\n",
    "️a) Training Set (70-80% of data)\n",
    "Used to train the model (learn patterns from data).\n",
    "The model adjusts its parameters using this data.\n",
    "️b) Testing Set (20-30% of data)\n",
    "Used to evaluate how well the model generalizes.\n",
    "If the model performs well on training data but poorly on testing data, it's overfitting.\n",
    "# Example of Train-Test Split in Python:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample dataset\n",
    "X = [[10], [20], [30], [40], [50]]  # Features\n",
    "y = [1, 0, 1, 0, 1]  # Labels\n",
    "\n",
    "# Split into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training Data:\", X_train)\n",
    "print(\"Testing Data:\", X_test)\n",
    "\n",
    "\n",
    "9. What is sklearn.preprocessing?\n",
    "    sklearn.preprocessing is a module in Scikit-Learn used for data preprocessing \n",
    "    (scaling, encoding, feature transformation).\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform([[200], [400], [600]])\n",
    "\n",
    "10. What is a Test Set?\n",
    "    A Test Set is a part of the dataset not used for training but for evaluating model performance.\n",
    "\n",
    "#Typical Split:\n",
    "\n",
    "Training Set: 70-80% (Used for learning)\n",
    "Testing Set: 20-30% (Used for evaluation)\n",
    "\n",
    "11. How do we split data for model fitting (training and testing) in Python?\n",
    "    Use train_test_split() from sklearn.model_selection:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "12. How do you approach a Machine Learning problem?\n",
    "    Step-by-step approach:                                                                 \n",
    "Define the problem (Regression / Classification).\n",
    "Perform EDA (Data exploration & visualization).\n",
    "Preprocess data (Handle missing values, scaling, encoding).\n",
    "Split data (train_test_split()).\n",
    "Choose a model (Logistic Regression, Decision Tree, etc.).\n",
    "Train the model (model.fit(X_train, y_train)).\n",
    "Evaluate performance (model.score(X_test, y_test)).\n",
    "Optimize (Hyperparameter tuning).\n",
    "Make predictions & deploy\n",
    "                                                                 ️\n",
    "13. Why do we have to perform EDA before fitting a model to the data?\n",
    "    Exploratory Data Analysis (EDA) helps:\n",
    "a) Detect missing values & outliers\n",
    "b) Identify correlations between features\n",
    "c) Choose the right features & transformations\n",
    "\n",
    "#Example:\n",
    "df.isnull().sum()  # Check missing values\n",
    "df.corr()  # Check correlation\n",
    "\n",
    "14. What is correlation?\n",
    "Correlation measures the relationship between two variables.\n",
    "\n",
    "a) Types:\n",
    "\n",
    "Positive Correlation (r > 0): Both increase (Height vs. Weight).\n",
    "Negative Correlation (r < 0): One increases, the other decreases (Temperature vs. Jacket Sales).\n",
    "No Correlation (r = 0): No relationship.\n",
    "\n",
    "15. What does negative correlation mean?\n",
    "    A negative correlation means that as one variable increases, the other decreases.\n",
    "\n",
    "#Example:\n",
    "\n",
    "Temperature vs. Jacket Sales (Higher temp = Fewer sales).\n",
    "Study Time vs. TV Time (More study = Less TV).\n",
    "#Mathematically: If r is negative, the correlation is negative.\n",
    "\n",
    "16. How can you find correlation between variables in Python?\n",
    "    Using Pandas corr()\n",
    "df.corr()\n",
    "#Using Seaborn Heatmap\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "\n",
    "\n",
    "17. What is Causation?\n",
    "    Causation means that one variable directly affects another (cause and effect relationship).\n",
    "#Difference Between Correlation & Causation:\n",
    "\n",
    "Concept\tMeaning\tExample:\n",
    "    Correlation\tTwo variables move together but may not be related\tIce cream sales &\n",
    "    drowning incidents (both increase in summer).\n",
    "Causation:\n",
    "    One variable directly influences the other\tMore studying → Higher exam scores.\n",
    "                                                                \n",
    "️18. What is an Optimizer? What are different types of optimizers?\n",
    "    An optimizer is an algorithm that adjusts model parameters to minimize loss and improve accuracy.\n",
    "\n",
    "#Types of Optimizers:\n",
    "\n",
    "Optimizer:\n",
    "Gradient Descent\tUpdates weights in the direction of the lowest loss\tUsed in Linear Regression.\n",
    "SGD (Stochastic Gradient Descent)\tUpdates weights using one random sample per step\tFaster but noisier.\n",
    "Adam (Adaptive Moment Estimation)\tCombines momentum & adaptive learning\tWorks well for deep learning.\n",
    "#Example (Using Adam Optimizer in TensorFlow):\n",
    "\n",
    "import tensorflow as tf\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "19. What is sklearn.linear_model?\n",
    "    sklearn.linear_model is a module in Scikit-Learn that provides algorithms for linear-based models.\n",
    "\n",
    "#Common Models:\n",
    "\n",
    "Linear Regression (LinearRegression())\n",
    "Logistic Regression (LogisticRegression())\n",
    "# Example (Linear Regression in Python):\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "20. What does model.fit() do? What arguments must be given?\n",
    "    The fit() method trains the model on given data.\n",
    "\n",
    " Arguments:\n",
    "model.fit(X_train, y_train)\n",
    "X_train: Features (input data).\n",
    "y_train: Labels (target variable).\n",
    "\n",
    "21. What does model.predict() do? What arguments must be given?\n",
    "    The predict() method makes predictions using a trained model.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "X_test: Input data for prediction.\n",
    "️\n",
    "22. What are continuous and categorical variables?\t\n",
    "    Continuous can take infinite values\tHeight, Salary, Temperature\n",
    "    Categorical\tFixed categories or groups\tGender (Male/Female), Colors (Red/Blue)\n",
    "\n",
    "23. What is Feature Scaling? How does it help in ML?\n",
    "    Feature Scaling normalizes or standardizes data to improve model performance.\n",
    "\n",
    "    Ensures all features have the same scale (avoids large differences).\n",
    "    Helps models like SVM, KNN, Neural Networks perform better.\n",
    "# Example:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "24. How do we perform scaling in Python?\n",
    "    Two common methods:\n",
    "\n",
    "Scaling Method\tPurpose\tExample\n",
    "Min-Max Scaling\tScales values between 0 and 1\tMinMaxScaler()\n",
    "Standard Scaling\tCenters data around mean 0, std 1\tStandardScaler()\n",
    "# Example (Min-Max Scaling in Python):\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "25. What is sklearn.preprocessing?\n",
    "    sklearn.preprocessing is a module in Scikit-Learn that provides functions for data preprocessing (scaling, encoding, transformation).\n",
    "\n",
    "    Common Functions:\n",
    "\n",
    "StandardScaler(): Standardizes data.\n",
    "MinMaxScaler(): Scales data between 0 and 1.\n",
    "LabelEncoder(): Converts categories to numbers.\n",
    "OneHotEncoder(): Converts categorical variables into binary columns.\n",
    "\n",
    "26. How do we split data for model fitting (training and testing) in Python?\n",
    "     Use train_test_split() from Scikit-Learn\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "Parameters:\n",
    "\n",
    "test_size=0.2: 20% of data goes to testing.\n",
    "random_state=42: Ensures reproducibility.\n",
    "\n",
    "27. Explain Data Encoding?\n",
    "    Data encoding converts categorical data into numerical values for ML models.\n",
    "\n",
    "Common Techniques:\n",
    "\n",
    "Encoding Type\tPurpose\tExample\n",
    "Label Encoding\tAssigns numbers to categories\t{'Male': 0, 'Female': 1}\n",
    "One-Hot Encoding\tCreates binary columns\tColor → [Red, Blue, Green] → [1, 0, 0]\n",
    "Target Encoding\tUses mean of target variable\tCity → [NY = 0.6, LA = 0.7]\n",
    "#Example (One-Hot Encoding in Python):\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb35c9-d265-4d9f-a49b-d60c7fbd4286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
